#!/command/with-contenv bash
#----------------------------------------------------------------------
# Container Logging Configuration
#
# Purpose: Configures logging services in the container environment:
# 1. Log rotation via logrotate
# 2. Log shipping via Fluent Bit
#
# This script handles both log management approaches independently.
# Log rotation can work without log shipping, and vice versa.
#----------------------------------------------------------------------

# Enable strict error handling
set -euo pipefail

#----------------------------------------------------------------------
# CONFIGURATION
#----------------------------------------------------------------------
# Source container functions library
source /assets/functions/00-container
output_off
prepare_service
PROCESS_NAME="logging"

#----------------------------------------------------------------------
# MAIN EXECUTION
#----------------------------------------------------------------------

#----------------------------------------------------------------------
# LOG ROTATION CONFIGURATION
#----------------------------------------------------------------------
if var_true "${CONTAINER_ENABLE_LOGROTATE}" ; then
  print_debug "Enabling log rotation"

  # Configure compression settings based on compression type
  case "${LOGROTATE_COMPRESSION_TYPE,,}" in
    bz* )
      # BZip2 compression
      logrotate_compression=$(cat<<EOF
compress
compresscmd $(which bzip2)
compressext .bz2
compressoptions -${LOGROTATE_COMPRESSION_VALUE} ${LOGROTATE_COMPRESSION_EXTRA_PARAMETERS}
EOF
      )
    ;;
    gz* )
      # GZip compression
      logrotate_compression=$(cat<<EOF
compress
compresscmd $(which gzip)
compressext .gz
compressoptions -${LOGROTATE_COMPRESSION_VALUE} ${LOGROTATE_COMPRESSION_EXTRA_PARAMETERS}
EOF
      )
    ;;
    none )
      # No compression
      logrotate_compression=""
    ;;
    zs* )
      # ZStandard compression
      logrotate_compression=$(cat<<EOF
compress
compresscmd $(which zstd)
compressext .zst
compressoptions -${LOGROTATE_COMPRESSION_VALUE} ${LOGROTATE_COMPRESSION_EXTRA_PARAMETERS}
EOF
      )
    ;;
  esac

  # Create main logrotate configuration
  cat <<EOF > /etc/logrotate.conf
daily
rotate ${LOGROTATE_RETAIN_DAYS}
copytruncate
dateext
nomail
notifempty
${logrotate_compression}
include /etc/logrotate.d
EOF

  # Set permissions on logrotate config
  chmod 0744 /etc/logrotate.conf

  # Create cron job to run logrotate daily
  mkdir -p "${CONTAINER_SCHEDULING_LOCATION}"
  cat <<EOF > "${CONTAINER_SCHEDULING_LOCATION}"/logrotate
# Hardcoded in image in /etc/cont-init.d/$(basename "$0")
# Generated on $(TZ=${TIMEZONE} date +'%Y-%m-%d %H:%M:%S %Z')

59 23 * * * logrotate -f /etc/logrotate.conf >/dev/null 2>&1
EOF
fi

#----------------------------------------------------------------------
# LOG SHIPPING CONFIGURATION
#----------------------------------------------------------------------
if var_false "${CONTAINER_ENABLE_LOGSHIPPING}" ;  then
  # Skip log shipping if disabled
  service_stop "$(basename "$0")"
else
  # Configure log shipping based on selected backend
  case "${CONTAINER_LOGSHIPPING_BACKEND,,}" in
    "fluent-bit" | "fluentbit" )
      #----------------------------------------------------------------------
      # FLUENT BIT - OS & ARCHITECTURE COMPATIBILITY CHECK
      #----------------------------------------------------------------------
      # Check OS and architecture compatibility for Fluent Bit
      os=$(cat /etc/os-release |grep ^ID= | cut -d = -f2)
      case ${os,,} in
        "alpine" )
          # Check Alpine architecture and version
          archit="$(apk --print-arch)"
          case "$archit" in
            x86_64)
              # Check Alpine version - must be 3.11+ or edge
              osver=$(cat /etc/os-release | grep VERSION_ID | cut -d = -f 2 | cut -d . -f 2 | cut -d _ -f 1)
              if [ "${osver}" -ge 11 ] || [ "$osver" = "edge" ] || [ "$osver" = "17*" ]; then
                :
              else
                print_error "Sorry this functionality is not available on < Alpine 3.11 releases"
                service_stop "$(basename "$0")"
                liftoff
                exit 0
              fi
            ;;
            *)
              # Architecture not supported
              print_error "Sorry this functionality is not available on ${archit} architecture"
              service_stop "$(basename "$0")"
              liftoff
              exit
            ;;
          esac
        ;;
        "debian" | "ubuntu" )
          # Check Debian/Ubuntu architecture
          archit=$(dpkg --print-architecture) && \
          case "$archit" in \
            amd64)
              :
            ;;
            *)
              # Architecture not supported
              print_error "Sorry this functionality is not available on ${archit} architecture"
              service_stop "$(basename "$0")"
              liftoff
              exit
            ;;
          esac
        ;;
      esac

      #----------------------------------------------------------------------
      # FLUENT BIT - MAIN CONFIGURATION
      #----------------------------------------------------------------------
      if [ "${FLUENTBIT_SETUP_TYPE,,}" = "auto" ] ; then
        print_debug "[logship] Configuring Fluent-bit agent"

        # Convert boolean settings to ON/OFF for Fluent Bit
        truefalse_onoff FLUENTBIT_ENABLE_HTTP_SERVER
        truefalse_onoff FLUENTBIT_ENABLE_STORAGE_METRICS
        truefalse_onoff FLUENTBIT_STORAGE_CHECKSUM

        # Create required directories
        mkdir -p "${FLUENTBIT_STORAGE_PATH}"
        mkdir -p "${FLUENTBIT_LOG_PATH}"
        mkdir -p /etc/fluent-bit/conf.d

        # Create initial config to avoid startup failure
        cat <<EOF > /etc/fluent-bit/conf.d/do_not_delete.conf
# Don't delete this configuration file otherwise execution of fluent-bit will fail. It will not affect operation of your system or impact resources
[INPUT]
    Name   dummy
    Tag    ignore

[FILTER]
    Name grep
    Match ignore
    regex ignore ignore

[OUTPUT]
    Name   NULL
    Match  ignore
EOF

        # Process custom parsers if they exist
        if [ "$(ls -A /etc/fluent-bit/parsers.d/)" ]; then
          shopt -s nullglob
          for custom_parser in /etc/fluent-bit/parsers.d/*.conf ; do
            print_debug "[logship] Found additional parser for '$(echo "${custom_parser,,}" | sed "s|.conf||g")'"
            additional_parsers=$(echo "${additional_parsers}" ; cat<<EOF
    parsers_file ${custom_parser}
EOF
            )
          done
          shopt -u nullglob
        fi

        # Create main Fluent Bit configuration
        cat <<EOF > /etc/fluent-bit/fluent-bit.conf
## Generated on $(TZ=${TIMEZONE} date +'%Y-%m-%d %H:%M:%S %Z')

@INCLUDE conf.d/*.conf
[SERVICE]
    daemon       Off
    flush        ${FLUENTBIT_FLUSH_SECONDS}
    grace        ${FLUENTBIT_GRACE_SECONDS}
    http_listen  ${FLUENTBIT_HTTP_LISTEN_IP}
    http_port    ${FLUENTBIT_HTTP_LISTEN_PORT}
    http_server  ${FLUENTBIT_ENABLE_HTTP_SERVER}
    log_file     ${FLUENTBIT_LOG_PATH}/${FLUENTBIT_LOG_FILE}
    log_level    ${FLUENTBIT_LOG_LEVEL}
    plugins_file ${FLUENTBIT_CONFIG_PLUGINS}
    storage.backlog.mem_limit ${FLUENTBIT_STORAGE_BACKLOG_LIMIT}
    storage.checksum ${FLUENTBIT_STORAGE_CHECKSUM}
    storage.metrics ${FLUENTBIT_ENABLE_STORAGE_METRICS}
    storage.path ${FLUENTBIT_STORAGE_PATH}
    storage.sync ${FLUENTBIT_STORAGE_SYNC}
    parsers_file ${FLUENTBIT_CONFIG_PARSERS}
${additional_parsers}
EOF

        #----------------------------------------------------------------------
        # FLUENT BIT - INPUT PLUGINS CONFIGURATION
        #----------------------------------------------------------------------
        case "${FLUENTBIT_MODE,,}" in
          "normal" )
            print_debug "[logship] Configuring Fluent-Bit for Normal/Client mode"

            # Configure tail input plugin options
            if var_true "${FLUENTBIT_TAIL_KEY_PATH_ENABLE}" ; then
              tail_key_path="    Path_Key          ${FLUENTBIT_TAIL_KEY_PATH}"
            fi

            if var_true "${FLUENTBIT_TAIL_KEY_OFFSET_ENABLE}" ; then
              tail_key_offset="    Offset_Key        ${FLUENTBIT_TAIL_KEY_OFFSET}"
            fi

            if [ -n "${FLUENTBIT_TAIL_IGNORE_OLDER}" ] ; then
              tail_ignore_older="    Ignore_Older      ${FLUENTBIT_TAIL_IGNORE_OLDER}"
            fi

            truefalse_onoff FLUENTBIT_TAIL_SKIP_EMPTY_LINES
            truefalse_onoff FLUENTBIT_TAIL_SKIP_LONG_LINES

            #----------------------------------------------------------------------
            # FLUENT BIT - PROCESS ENV VARIABLES FOR LOG FILES
            #----------------------------------------------------------------------
            # Process LOGSHIP_ environment variables for log files to monitor
            logshipenv=$(mktemp)
            set -o posix; set -f
            set | grep -E '^LOGSHIP_'| sed "s|LOGSHIP_||g" > "${logshipenv}"

            while IFS= read -r logship_entry; do
              logship_title="$(echo "${logship_entry}" | cut -d = -f1 | tr '[:upper:]' '[:lower:]' )"
              logship_value="$(echo "${logship_entry}" | cut -d = -f2 )"
              logship_value="$(echo "${logship_value:1:-1}")"

              if var_false "${logship_value}" ; then
                # Create disabled log file entry
                print_debug "[logship] Disabling ${logship_title} Log Shipping"
                cat <<EOF > "/etc/fluent-bit/conf.d/in_tail_${logship_title,,}.conf"
# Nulled Log Monitoring of ${logship_title} generated by Environment Variable defined in Image build, or Runtime argument
# Generated on $(TZ=${TIMEZONE} date +'%Y-%m-%d %H:%M:%S %Z')
EOF
                # Update logrotate configuration if it exists
                if [ -f "/assets/logrotate/${logship_title,,}" ] ; then
                  print_debug "[logship] Setting Logrotate value to skip for /assets/logrotate/${logship_title,,}"
                  sed -i "# logship: .*|# logship: ignore"
                fi
              else
                # Create active log file entry
                print_debug "[logship] Adding ${logship_title} with to be parsed by ${CONTAINER_LOGSHIPPING_BACKEND}"

                # Configure database settings for tail plugin if enabled
                if var_true "${FLUENTBIT_TAIL_DB_ENABLE}" ; then
                  tail_db=$(cat<<EOF
    DB                $(dirname ${logship_value})/.$(basename ${logship_value}).db
    DB.sync           ${FLUENTBIT_TAIL_DB_SYNC}
    DB.locking        ${FLUENTBIT_TAIL_DB_LOCK}
    DB.journal_mode   ${FLUENTBIT_TAIL_DB_JOURNAL_MODE}
EOF
                  )
                fi

                # Create tail input configuration for this log file
                cat <<EOF > "/etc/fluent-bit/conf.d/in_tail_${logship_title,,}.conf"
# Log File Monitoring created automatically generated by Environment Variable defined in Image build, or Runtime argument
# Entered Value: ${logship_value}
# Generated on $(TZ=${TIMEZONE} date +'%Y-%m-%d %H:%M:%S %Z')

[INPUT]
    Name              tail
    Path              ${logship_value}
    Tag               ${logship_title,,}
    Buffer_Chunk_Size ${FLUENTBIT_TAIL_BUFFER_CHUNK_SIZE}
    Buffer_Max_Size   ${FLUENTBIT_TAIL_BUFFER_MAX_SIZE}
    Read_from_Head    ${FLUENTBIT_TAIL_READ_FROM_HEAD}
    Skip_Empty_Lines  ${FLUENTBIT_TAIL_SKIP_EMPTY_LINES}
    Skip_Long_Lines   ${FLUENTBIT_TAIL_SKIP_LONG_LINES}
${tail_key_path}
${tail_db}
${tail_ignore_older}
${tail_key_offset}

[FILTER]
    Name record_modifier
    Match ${logship_title,,}
    Record hostname $(hostname)
    Record container_name ${CONTAINER_NAME}
    Record product ${logship_title,,}

EOF
              fi
            done < "${logshipenv}"

            # Clean up
            rm -rf "$logshipenv"
            set +f
            unset logshipenv logship_entry logship_value logship_title db
            unset "${!LOGSHIP_@}"

            #----------------------------------------------------------------------
            # FLUENT BIT - PROCESS DEFAULT FILES FOR LOG ENTRIES
            #----------------------------------------------------------------------
            # Process LOGSHIP_ variables from defaults files
            for d in /assets/defaults/* ; do
              if [ "$d" != "/assets/defaults/00-container" ] ; then
                # Source the defaults file
                source "$d"
                logshipenv=$(mktemp)
                set -o posix; set -f
                set | grep -E '^LOGSHIP_'| sed "s|LOGSHIP_||g" > "${logshipenv}"

                while IFS= read -r logship_entry; do
                  logship_title="$(echo "${logship_entry}" | cut -d = -f1 | tr '[:upper:]' '[:lower:]')"
                  logship_value="$(echo "${logship_entry}" | cut -d = -f2 )"
                  logship_value="$(echo "${logship_value:1:-1}")"

                  # Configure database settings if enabled
                  if var_true "${FLUENTBIT_TAIL_DB_ENABLE}" ; then
                    tail_db=$(cat<<EOF
    DB                $(dirname ${logship_value})/.$(basename ${logship_value}).db
    DB.sync           ${FLUENTBIT_TAIL_DB_SYNC}
    DB.locking        ${FLUENTBIT_TAIL_DB_LOCK}
    DB.journal_mode   ${FLUENTBIT_TAIL_DB_JOURNAL_MODE}
EOF
                    )
                  fi

                  # Create configuration only if it doesn't already exist
                  if [ ! -f "/etc/fluent-bit/conf.d/in_tail_${logship_title,,}.conf" ] ; then
                    print_debug "[logship] Adding ${logship_title} with to parsed by ${CONTAINER_LOGSHIPPING_BACKEND}"
                    cat <<EOF > "/etc/fluent-bit/conf.d/in_tail_${logship_title,,}.conf"
# Log File Shipping created automatically generated by reading through defaults in /assets/defaults/*
# Entered Value: ${logship_value}
# Generated on $(TZ=${TIMEZONE} date +'%Y-%m-%d %H:%M:%S %Z')

[INPUT]
    Name              tail
    Path              ${logship_value}
    Tag               ${CONTAINER_NAME}_${logship_title,,}
    Buffer_Chunk_Size ${FLUENTBIT_TAIL_BUFFER_CHUNK_SIZE}
    Buffer_Max_Size   ${FLUENTBIT_TAIL_BUFFER_MAX_SIZE}
    Read_from_Head    ${FLUENTBIT_TAIL_READ_FROM_HEAD}
    Skip_Empty_Lines  ${FLUENTBIT_TAIL_SKIP_EMPTY_LINES}
    Skip_Long_Lines   ${FLUENTBIT_TAIL_SKIP_LONG_LINES}
${tail_key_path}
${tail_db}
${tail_ignore_older}
${tail_key_offset}
EOF
                  else
                    print_debug "[logship] Skipping adding ${logship_title} as it already exists"
                  fi
                done < "${logshipenv}"

                # Clean up
                rm -rf "$logshipenv"
                set +f
                unset logshipenv logship_entry logship_value logship_title
                unset "${!LOGSHIP_@}"
              fi
            done
          ;;
          "proxy" | "forward" )
            #----------------------------------------------------------------------
            # FLUENT BIT - FORWARD INPUT CONFIGURATION (PROXY MODE)
            #----------------------------------------------------------------------
            print_debug "[logship] Configuring Fluent-Bit for Proxy/Forwarding Mode"
            cat <<EOF > /etc/fluent-bit/conf.d/in_forward.conf
[INPUT]
    Name forward
    Listen 0.0.0.0
    Port ${FLUENTBIT_FORWARD_PORT}
    Buffer_Chunk_Size ${FLUENTBIT_FORWARD_BUFFER_CHUNK_SIZE}
    Buffer_Max_Size   ${FLUENTBIT_FORWARD_BUFFER_MAX_SIZE}
EOF
          ;;
        esac

        #----------------------------------------------------------------------
        # FLUENT BIT - OUTPUT PLUGINS CONFIGURATION
        #----------------------------------------------------------------------
        case "${FLUENTBIT_OUTPUT,,}" in
          "loki" )
            # Configure Loki output plugin
            transform_file_var \
              FLUENTBIT_OUTPUT_LOKI_HOST \
              FLUENTBIT_OUTPUT_LOKI_PORT \
              FLUENTBIT_OUTPUT_LOKI_USER \
              FLUENTBIT_OUTPUT_LOKI_PASS \
              FLUENTBIT_OUTPUT_LOKI_TENANT_ID

            # Set optional authentication parameters if defined
            if [ -n "${FLUENTBIT_OUTPUT_LOKI_USER}" ] ; then
              loki_user="    http_user              ${FLUENTBIT_OUTPUT_LOKI_USER}"
            fi

            if [ -n "${FLUENTBIT_OUTPUT_LOKI_PASS}" ] ; then
              loki_pass="    http_passwd            ${FLUENTBIT_OUTPUT_LOKI_PASS}"
            fi

            if [ -n "${FLUENTBIT_OUTPUT_LOKI_TENANT_ID}" ] ; then
              loki_tenant_id="    tenant_id              ${FLUENTBIT_OUTPUT_LOKI_TENANT_ID}"
            fi

            # Convert boolean settings to ON/OFF
            truefalse_onoff FLUENTBIT_OUTPUT_LOKI_TLS
            truefalse_onoff FLUENTBIT_OUTPUT_LOKI_TLS_VERIFY
            truefalse_onoff FLUENTBIT_OUTPUT_LOKI_COMPRESS_GZIP

            # Create Loki output configuration
            cat <<EOF > /etc/fluent-bit/conf.d/out_loki.conf
## Auto generated LOKI Output plugin for Fluent Bit
## Generated on $(TZ=${TIMEZONE} date +'%Y-%m-%d %H:%M:%S %Z')

[OUTPUT]
    name                   loki
    match                  *
    host                   ${FLUENTBIT_OUTPUT_LOKI_HOST}
    port                   ${FLUENTBIT_OUTPUT_LOKI_PORT}
    tls                    ${FLUENTBIT_OUTPUT_LOKI_TLS,,}
    tls.verify             ${FLUENTBIT_OUTPUT_LOKI_TLS_VERIFY,,}
    compress               ${FLUENTBIT_OUTPUT_LOKI_COMPRESS_GZIP,,}
    labels                 logshipper=${CONTAINER_NAME}
    Label_keys             \$hostname,\$container_name,\$product
${loki_user}
${loki_pass}
${loki_tenant_id}

EOF
          ;;
          "fluentd" | "forward" )
            # Configure Forward output plugin for Fluentd
            truefalse_onoff FLUENTBIT_OUTPUT_FORWARD_TLS
            truefalse_onoff FLUENTBIT_OUTPUT_FORWARD_TLS_VERIFY

            # Add shared secret if defined
            if [ ! -z "${FLUENTBIT_OUTPUT_FORWARD_SECRET}" ] ; then
              forward_secret="    Shared_Key    ${FLUENTBIT_OUTPUT_FORWARD_SECRET}"
            fi

            # Process host variable if from file
            transform_file_var FLUENTBIT_OUTPUT_FORWARD_HOST

            # Create Forward output configuration
            cat <<EOF > /etc/fluent-bit/conf.d/out_forward.conf
## Auto generated FluentD Forward Output plugin for Fluent Bit
## Generated on $(TZ=${TIMEZONE} date +'%Y-%m-%d %H:%M:%S %Z')

[OUTPUT]
    Name          forward
    Match         *
    Host          ${FLUENTBIT_OUTPUT_FORWARD_HOST}
    Port          ${FLUENTBIT_FORWARD_PORT}
    Self_Hostname ${CONTAINER_NAME}
    tls           ${FLUENTBIT_OUTPUT_FORWARD_TLS,,}
    tls.verify    ${FLUENTBIT_OUTPUT_FORWARD_TLS_VERIFY,,}
${forward_secret}
EOF
          ;;
          "null" )
            # Configure Null output plugin (discard logs)
            cat <<EOF > /etc/fluent-bit/conf.d/out_null.conf
## Auto generated NULL Output plugin for Fluent Bit
## Generated on $(TZ=${TIMEZONE} date +'%Y-%m-%d %H:%M:%S %Z')

[OUTPUT]
    Name null
    Match *
EOF
          ;;
        esac
      else
        # Manual configuration mode - minimal setup
        print_notice "[logship] Not auto configuring Fluent-Bit. Drop configuration files in /etc/fluent-bit/conf.d"
        cat <<EOF > /etc/fluent-bit/fluent-bit.conf
## This configuration file allows you to put your own configuration in /etc/fluent-bit/conf.d - Don't delete or it will fail :)
## Generated on $(TZ=${TIMEZONE} date +'%Y-%m-%d %H:%M:%S %Z')
@INCLUDE conf.d/*.conf
EOF
      fi

      #----------------------------------------------------------------------
      # FLUENT BIT - FINALIZATION
      #----------------------------------------------------------------------
      # Set up log rotation for fluent-bit logs
      create_logrotate fluentbit "${FLUENTBIT_LOG_PATH}"/"${FLUENTBIT_LOG_FILE}"

      # Set up monitoring if enabled
      if var_true "${CONTAINER_ENABLE_MONITORING}" && [ "${CONTAINER_MONITORING_BACKEND,,}" = "zabbix" ]; then
        cat <<EOF > "${ZABBIX_CONFIG_PATH}"/"${ZABBIX_CONFIG_FILE}".d/focela-fluentbit.conf
# Zabbix Fluentbit Configuration - Automatically generated based on container startup options
# Find Companion Zabbix Server Templates at https://github.com/focela/docker-alpine or https://github.com/focela/docker-debian
# Autoregister=fluentbit
EOF
      fi

      print_notice "Container configured to ship logs via '${CONTAINER_LOGSHIPPING_BACKEND}'"
    ;;
    *)
      # Unknown backend
      print_error "[logship] Unknown Log Shipping Backend"
      exit 1
    ;;
  esac
fi

# Mark initialization as complete
liftoff
output_on
